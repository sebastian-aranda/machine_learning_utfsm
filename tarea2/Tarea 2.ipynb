{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Integrantes\n",
    "<ul>\n",
    "<li>Sebasti치n Aranda 201104560-2</li>\n",
    "<li>Felipe Santander 201104xxx-x</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fronteras de Clasificaci칩n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.utils import check_random_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples=500\n",
    "\n",
    "#Generating Multivariate Normal Distribution\n",
    "mean = (0,-4)\n",
    "C = np.array([[0.3, 0.1], [0.1, 1.5]])\n",
    "datos1 = np.random.multivariate_normal(mean, C, n_samples)\n",
    "\n",
    "#Generating Halfmoon Distribution\n",
    "outer_circ_x = np.cos(np.linspace(0, np.pi, n_samples))*3\n",
    "outer_circ_y = np.sin(np.linspace(0, np.pi, n_samples))*3\n",
    "datos2 = np.vstack((outer_circ_x,outer_circ_y)).T\n",
    "generator = check_random_state(10)\n",
    "datos2 += generator.normal(scale=0.3, size=datos2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.85803502 -6.05367156]\n",
      " [ 0.25564747 -3.61507543]\n",
      " [ 0.19303284 -3.62600551]\n",
      " [ 0.0144274  -3.74972932]\n",
      " [ 0.73715416 -3.44669869]\n",
      " [ 0.27500295 -2.95442209]\n",
      " [-0.472739   -4.51819502]\n",
      " [-0.0698811  -4.28150706]\n",
      " [-0.42769563 -3.3871854 ]\n",
      " [ 0.93478617 -2.15019779]\n",
      " [-0.38761342 -3.8458653 ]\n",
      " [-0.95347659 -4.62888575]\n",
      " [ 0.1199105  -4.18126579]\n",
      " [-0.75843514 -4.37596287]\n",
      " [-0.2739062  -4.54865006]\n",
      " [-0.37627462 -4.14621062]\n",
      " [ 0.69156277 -4.7657318 ]\n",
      " [-0.15363903 -5.27695445]\n",
      " [ 0.16843266 -3.85521083]\n",
      " [-0.02921227 -4.75325179]\n",
      " [ 0.24525271 -6.86793776]\n",
      " [-0.623821   -3.59685809]\n",
      " [ 0.59663635 -3.35210213]\n",
      " [-1.16123267 -3.77559397]\n",
      " [ 0.14920226 -5.51676329]\n",
      " [ 0.46670441 -2.39051178]\n",
      " [ 0.70335005 -3.12692867]\n",
      " [ 0.18606275 -5.81519934]\n",
      " [ 0.48809908 -5.13861861]\n",
      " [-0.40169683 -2.66618392]]\n",
      "[[ 3.39947595  0.21458369]\n",
      " [ 2.53632046  0.01637205]\n",
      " [ 3.18616297 -0.17825201]\n",
      " [ 3.07911839  0.08922318]\n",
      " [ 3.0003362   0.02316127]\n",
      " [ 3.1284216   0.45533227]\n",
      " [ 2.70834017  0.42177926]\n",
      " [ 3.06567621  0.26570981]\n",
      " [ 2.65521501  0.19157583]\n",
      " [ 3.44054652 -0.15404643]\n",
      " [ 2.40073796 -0.33426313]\n",
      " [ 3.07262984  0.9230848 ]\n",
      " [ 3.3285499   0.72821909]\n",
      " [ 3.01970244  0.66466018]\n",
      " [ 2.90697992  0.44804164]\n",
      " [ 2.90643736  0.11809634]\n",
      " [ 3.02460482  0.15884388]\n",
      " [ 3.37537576  0.37897595]\n",
      " [ 3.10082012  0.23795504]\n",
      " [ 3.35550393  0.13841323]\n",
      " [ 3.17431879  0.27148766]\n",
      " [ 2.69198842  0.24867827]\n",
      " [ 2.72989231  0.35038468]\n",
      " [ 2.86686104  0.52654307]\n",
      " [ 3.13536471  0.40734697]\n",
      " [ 2.95514554  0.55696437]\n",
      " [ 2.79793422  0.70132854]\n",
      " [ 3.20942884  0.56857982]\n",
      " [ 3.6719188   0.80134819]\n",
      " [ 2.91645517  0.43604045]]\n"
     ]
    }
   ],
   "source": [
    "print(datos1[:30])\n",
    "print(datos2[:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = np.concatenate((datos1, datos2), axis=0)\n",
    "n = 20 #Noise\n",
    "y1 = np.zeros(datos1.shape[0]+n)\n",
    "y2 = np.ones(datos2.shape[0]-n)\n",
    "y = np.concatenate((y1,y2),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def visualize_border(model,x,y,title=\"\"):\n",
    "    fig = plt.figure(figsize=(12,6))\n",
    "    plt.scatter(x[:,0], x[:,1], s=50, c=y, cmap=plt.cm.winter)\n",
    "    h = .02 # step size in the mesh\n",
    "    x_min, x_max = x[:, 0].min() - 1, x[:, 0].max() + 1\n",
    "    y_min, y_max = x[:, 1].min() - 1, x[:, 1].max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),np.arange(y_min, y_max, h))\n",
    "    \n",
    "    Z = model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    plt.contour(xx, yy, Z, cmap=plt.cm.Paired)\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "model = LDA()\n",
    "model.fit(X,y)\n",
    "visualize_border(model,X,y,\"LDA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis as QDA\n",
    "model = QDA()\n",
    "model.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Miss Classification Loss: %f\"%(1-accuracy_score(y_true, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from ipywidgets import interactive\n",
    "def visualize_border_interactive(param):\n",
    "    model = train_model(param)\n",
    "    visualize_border(model,X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression as LR\n",
    "def train_model(param):\n",
    "    model=LR() #define your model\n",
    "    model.set_params(C=param,penalty='l2')\n",
    "    model.fit(X,y)\n",
    "    return model\n",
    "\n",
    "p_min = #define your range\n",
    "p_max = #define your range\n",
    "interactive(visualize_border_interactive,param=(p_min,p_max))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An치lisis de Audio - Datos Brutos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An치lisis de Emociones - Twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
